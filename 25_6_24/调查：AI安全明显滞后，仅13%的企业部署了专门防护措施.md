 # AI安全滞后于AI发展：危机与挑战

## 一、事件概要

根据云安全公司Wiz最新调查报告显示，尽管87%的组织已在云端采用AI服务，但仅有不到七分之一(13%)的企业部署了专门的AI安全控制措施。这一现象反映出当前AI技术发展与AI安全防护之间存在明显差距，尤其是在影子AI激增和混合云架构日益复杂的背景下，安全团队在专业技能和工具方面的短板可能会对企业AI项目的顺利推进造成重大影响。

## 二、事件描述分析

### 2.1 AI应用普及与安全能力不匹配

调查数据显示，87%的组织已经在使用OpenAI、Amazon Bedrock等AI服务，这表明AI技术已经深入企业核心业务环节。然而，31%的受访者将"缺乏AI安全专业知识"列为他们面临的最大挑战，这也是被提及次数最多的问题。

这种情况导致安全团队面临一个棘手的困境：他们被要求保护一些他们并不完全了解的系统，而这一技能缺口正在不断扩大企业的风险暴露面。在专业人才培养跟不上技术发展速度的情况下，自动化工具和技术手段的重要性愈发凸显。

### 2.2 传统安全措施仍占主导地位

报告中的数据反映出一个值得关注的现象：仅有13%的组织使用AI专属安全态势管理（AI-SPM）工具，而大多数组织依然依赖适用于传统环境的控制手段，包括安全开发实践(53%)、租户隔离(41%)以及通过审计识别影子AI(35%)。

尽管这些传统措施依旧具有重要意义，但报告强调，它们并未针对AI系统的独特风险进行设计，例如模型横向访问、训练数据中毒以及未受监控的生成式API使用。这表明当前企业安全架构与AI技术特性之间存在结构性不匹配，无法有效应对AI特有的安全威胁。

### 2.3 云架构复杂化加剧安全挑战

随着混合云与多云部署已成为常态，调查显示45%的组织运行在混合云架构下，33%采用多云架构。然而，70%的受访组织主要依赖CDM端点检测与响应（EDR）平台，而这类工具本是为集中式架构设计的。

更值得警惕的是，有25%的受访者坦言，他们并不清楚当前环境中运行了哪些AI服务。这种缺乏可视性的状况在复杂的云架构环境中尤为危险，因为未知即意味着无法防护。

### 2.4 AI安全需求超越纯技术范畴

调查显示，组织对AI安全工具的核心诉求，已经反映出更广泛的运维与工作流程需求：69%的受访者将数据隐私视为首要需求，62%关注威胁的可视性，51%要求工具易于集成。

报告指出，难以与DevOps工作流集成，是AI安全工具推广面临的主要障碍。同时，去中心化、实验性质的AI开发模式也制造出传统安全体系难以覆盖的盲区。这表明AI安全不仅是技术问题，更是流程、组织和管理问题。

### 2.5 AI安全成熟度模型及现状评估

Wiz将AI安全准备度纳入其更广泛的云安全成熟度框架，定义了四个AI安全成熟阶段：
1. 实验性AI：高风险使用AI，缺乏可见性，存在影子部署
2. 初步治理：已建立基本控制措施，但尚未有效管理AI特有风险
3. AI集成安全：控制措施实现集成，已使用AI-SPM工具，治理水平明显提升
4. 主动AI安全运营：跨环境实现自动化，实时响应AI风险

报告指出，目前大多数组织仍停留在第1或第2阶段。这意味着大多数企业在AI安全领域仍处于起步阶段，与AI技术的快速发展形成鲜明对比。

## 三、对中国影响分析研判

### 3.1 中国AI发展与安全面临相似挑战

中国作为全球AI发展的重要力量，与报告中描述的情况有着诸多相似之处。随着中国企业广泛应用各类大模型和AI服务，特别是国产大模型的快速发展，企业面临的AI安全挑战可能比报告所描述的更为复杂。

从政策层面看，中国已经认识到AI安全的重要性，发布了《生成式人工智能服务管理暂行办法》等法规，但企业层面的安全实践与技术发展之间的差距仍然存在。中国企业同样面临着AI安全专业人才短缺、传统安全架构与AI特性不匹配、混合云架构下安全可视性不足等问题。

### 3.2 中国特色的AI安全挑战

相比于报告中的全球情况，中国在AI安全领域还面临一些独特挑战：

1. **数据安全与隐私保护压力更大**：随着《个人信息保护法》和《数据安全法》的实施，中国企业在使用AI时面临更严格的数据合规要求，需要在创新与合规之间寻找平衡。

2. **自主可控需求带来的挑战**：国产替代与技术自主可控的战略导向，要求企业更多使用国产AI工具和安全产品，这在短期内可能加剧专业能力和工具缺口。

3. **跨境数据流动限制的影响**：数据本地化要求使中国企业难以直接采用国际主流的AI安全工具和服务，增加了安全防护的难度。

4. **行业差异化明显**：中国金融、医疗、政务等重点行业对AI安全的要求远高于一般企业，而这些行业恰恰是AI应用最广泛的领域，使得安全挑战更为突出。

### 3.3 对中国AI产业发展的潜在影响

如果AI安全问题得不到有效解决，可能对中国AI产业带来以下影响：

1. **制约AI创新速度**：安全顾虑可能导致一些高风险但创新性强的AI应用受到限制或延迟推出。

2. **增加企业合规成本**：企业需要投入更多资源以满足AI安全和隐私合规要求，提高了AI应用的整体成本。

3. **安全事件风险增加**：随着AI应用普及但安全措施不足，各类AI安全事件可能增多，损害行业声誉和用户信任。

4. **拉大头部企业与中小企业差距**：大型科技公司有能力建立专业的AI安全团队，而中小企业在安全资源匮乏下可能被迫减少AI创新。

## 四、应对策略

### 4.1 国家层面策略建议

1. **制定AI安全标准体系**：加快制定覆盖AI全生命周期的安全标准，为企业提供明确的安全实践指南。

2. **建立国家级AI安全能力评估中心**：为企业提供权威的AI安全评估服务，推动行业安全能力提升。

3. **加大AI安全人才培养力度**：支持高校设立AI安全专业，鼓励企业与高校合作培养专业人才。

4. **促进AI安全技术研发**：设立专项资金支持AI安全基础研究和应用研究，加快安全技术创新。

5. **加强国际合作**：在保障国家安全的前提下，参与全球AI安全治理，吸收国际先进经验和技术。

### 4.2 企业层面实施建议

1. **建立专门的AI安全团队**：组建跨部门AI安全专家团队，负责制定和实施企业AI安全策略。

2. **参照成熟度模型评估现状**：基于报告中提出的AI安全成熟度模型，评估企业当前所处阶段，制定针对性提升计划。

3. **采用AI专属安全工具**：根据报告建议，企业应借助工具持续发现AI模型及影子服务；将安全"左移"，从软件开发生命周期早期就介入；确保安全策略能够在多云与混合环境中随工作负载迁移；为安全团队提供专门的AI安全培训。

4. **实施AI应用全生命周期安全管理**：从数据收集、模型训练到部署和监控，全流程嵌入安全控制措施。

5. **构建威胁情报共享机制**：主动参与行业威胁情报共享，提高对新型AI安全威胁的预警能力。

### 4.3 技术层面解决方案

1. **发展AI安全态势感知平台**：针对AI特有的安全风险，开发专门的安全态势管理平台，提高可视性。

2. **强化数据安全防护**：实施严格的数据访问控制和脱敏措施，防止模型训练数据中毒和数据泄露。

3. **开发AI模型防护技术**：研发针对模型提取、对抗样本、推理隐私等威胁的防护技术。

4. **建设安全可信的AI开发环境**：构建支持安全编码实践的AI开发环境，减少代码级安全漏洞。

5. **实施持续的安全测试与验证**：对AI系统进行持续的安全测试，包括渗透测试、模糊测试和红队演练。

## 五、结论

AI安全与AI技术发展之间的差距已经成为制约AI健康发展的关键因素。云安全公司Wiz的调查报告不仅揭示了全球企业在AI安全领域面临的共性挑战，也对中国企业提出了重要警示。

当前，中国企业在AI安全方面大多仍处于初级阶段，缺乏专业人才、工具和成熟的管理流程。随着AI技术在各行业的深入应用，这一安全短板可能带来严重后果。因此，政府、企业和技术社区需要形成合力，共同推动AI安全能力建设。

从长远来看，AI安全不应被视为AI发展的阻碍，而应成为支撑AI可持续发展的基础设施。只有建立起与AI技术发展相匹配的安全防护体系，才能确保AI创新在安全可控的环境中持续推进，最终实现技术进步与安全保障的良性循环。

正如报告总结所言："安全不能只是被动响应，必须持续推进，积极应对。"这一理念同样适用于中国的AI安全建设，唯有前瞻性布局、系统性规划，才能在全球AI竞争中保持技术先进性的同时，确保国家安全和用户权益。